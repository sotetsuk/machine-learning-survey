# How to explain individual classification decisions
- author:
- year: 2010
- citation: 48 (2016年6月 時点)
- [pdf](http://www.jmlr.org/papers/volume11/baehrens10a/baehrens10a.pdf)

[![How to explain individual classification decisions](../tmb/How to explain individual classification decisions.png)](http://www.jmlr.org/papers/volume11/baehrens10a/baehrens10a.pdf)
This thumbnail was generated by [paper2tmb](https://github.com/sotetsuk/paper2tmb) from [this page](http://www.jmlr.org/papers/volume11/baehrens10a/baehrens10a.pdf)

## 1. どんなもの？
個別の（サンプル一つの）予測に対する説明をするベクトル（local explanation vector）を提案した。
これによって、各サンプルがどのようにデータ空間で動けば特定のクラスのサンプルに近づくかを示せるようになった。

## 2. 先行研究と比べて何がすごい？
低次元、（特にニクラス）における任意の生成モデルの説明を可能にした。

## 3. 技術や手法のキモはどこ？
各サンプル点で勾配をとっているだけといえばそれだけだが、シンプルなので解釈が容易。

## 4. どうやって有効だと検証した？
二次元のToyデータ、Irisデータ、ニクラスの手書き文字認識のデータと多次元の実データを使って有効性を示した。
特に二次元では各サンプルに矢印（local explanation vector）を図示することで、どうサンプルが動けば特定のクラスに近づくかを示し、
手書き文字認識では実際にlocal explanation vectorの方に少しずつずらしていってその変化をみた。

## 5. 議論はある？
- 多次元のときにうまくいかないような気がする。
- 低次元でも、確率の予測値をただヒートマップにプロットしたものと比べた時のメリットが良くわからない。
- 手書き文字認識で少しずつ可視化をずらしていっている図では、常にサンプルの点における勾配の方向にずらしていっているわけだが、本来は直線ではなく曲がっているはず（データ空間上の位置に依存するはず）なのでベストとは言えないはず。

## 6. 次に読むべき論文は？
