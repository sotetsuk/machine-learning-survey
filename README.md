# 機械学習論文サーベイ
個人的に読んだ（流し読み含む）論文のまとめ（2017/02/04〜）

## まとめ一覧

### 年代毎
とりあえず読んだものなどを年代別にひと言コメントを添えて列挙したもの

- [Reinforcement Learning](year/rl.md)
  - 強化学習の主要な論文をすべて網羅することを目標にする
- [Seq2Seq](year/seq2seq.md)
  - 自分の興味のあるものを中心にSeq2Seqの手法に関する論文や応用論文をまとめる
- [Inbox](year/inbox.md)
  - 上記と関係のないものを読んだらとりあえずここに

### トピック毎
トピック毎にいくつか論文をまとめ、それらに対してコメントと比較を行ったもの

- [中脳の報酬系とTD学習](topic/td-dopamine.md)
- [Atari Montezuma's Revengeの攻略](topic/montezuma.md)
- [系列の予測と強化学習](topic/sequence-rl.md)
<!-- - [ニューラル文法誤り訂正](neural-grammatical-error-correction.md) -->
<!-- - [最近の難関国際会議のベストペーパーまとめ]() -->
<!-- - [VATまとめ]() -->
<!-- - [GANまとめ]() -->
<!-- - [論文の書き方が参考になるものまとめ]() -->

<!-- ### 論文毎 -->

## まとめの方針

### 年代毎
基本的に一論文につき次の観点に基づいて数行でまとめる（1,3,4は必須）

1. 何をしたのか？（一体どういったことをしている論文なのかをひと言で）
  - コントリビューションもここに含まれると良い
2. 何故したのか？（何故この研究をしたのか・何故その手法を提案したのかの理由をひと言で）
3. どうやってしたのか？（手法のキモとなるアイディアをひと言で）
4. どうなったのか？（結果がどういう指標で、どうだったのかをひと言で）
5. どう思ったのか（主張が素直に受け入れられない点や、改善点など）

それより細かい内容についてメモを残したくなったときや、いくつかの同じトピックの論文についてまとめたくなった時は新しくまとめを作る（下記）

### テーマ毎
とりあえず読んで年代別に加えていったもののうち、特定のトピックで共通性があり、それらの関係性などについてまとめたくなったら新しくこちらにまとめを作る。
数式が書けないので、基本的には文章中心。今のところ特にフォーマットは決めずに柔軟に書く。

#### テーマ毎まとめの書き方の参考記事
- [自然言語処理における畳み込みニューラルネットワークを用いたモデル](http://qiita.com/Hironsan/items/63d255fd038acbcdf95b)
- [半教師あり学習のモデル仮定](http://yamaguchiyuto.hatenablog.com/entry/machine-learning-advent-calendar-2014)

<!--
### 論文毎
- より詳細に読んだり、実装したくなったとき用のまとめ
- 要フォーマット整備
- 数式が書けないので論文紹介などを見越してBeamer等にまとめた方がいいかも
- もしくは実装などは大人しくQiitaに投稿した方がいいかもしれない
-->

## 更新方法
基本的にはsubscribeしてくれた人の通知欄が、通知を見るだけでどういった内容が反映されたのか分かるようにしたい。

### Issue
- Issueタイトルは論文のタイトル
- 本文に論文へのリンクを貼る
- 本文に何故読みたいと思ったのかを簡単に書く

### Commit
- Commitメッセージは基本的に論文名かトピック名を明示して何について加筆したのか分かりやすいように。
